{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The outputs generated by the lab.js contain a number of columns, which may not be required for our\n",
    "analysis. This basic notebook extracts relevant fields, removes identifying information, \n",
    "and converts all the delay information to a common time scale. \n",
    "The result is then written into separate .csvs, which can be used for model building and further analysis.\n",
    "Author: Aishwarya Seth\n",
    "Email: aseth5@jhu.edu\n",
    "Date of Creation: 7th April, 2022'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aishwaryaseth/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Import all relevant packages for this step\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all files containing experimental data\n",
    "files = glob.glob(\"./../Experimental_Data/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file_count is used as a unique identifier for each participant\n",
    "file_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each file, \n",
    "for file in files: \n",
    "    # Read in all rows in the output dataframe\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Select rows with responses for the Form, using 'sender' value 'Form' & store the row in df_info\n",
    "    # Select rows with choice information, using 'sender' value 'Choice' & store the rows in df_choices\n",
    "    df_info = df[df['sender'] == (\"Form\")]\n",
    "    df_choices = df[df['sender'] == \"Choice\"]\n",
    "    \n",
    "    # Drop all irrelevant columns for both data bases \n",
    "    df_info = df_info.drop(['sender', 'sender_type', 'sender_id', 'timestamp', 'meta', 'duration', 'ended_on',\n",
    "       'response', 'response_action', 'time_commit', 'time_end', 'time_render',\n",
    "       'time_run', 'time_show', 'time_switch', 'url', 'Amount', 'Delay', 'ID'], axis = 1)\n",
    "    \n",
    "    df_choices = df_choices.drop(['sender', 'sender_type', 'sender_id', 'timestamp', 'meta', 'Age', 'Degree', 'Essentials', 'Happiness', 'ID',\n",
    "       'Investments', 'Leisure', 'Sleep', 'Stress', 'response_action',  'time_commit', 'time_end', 'time_render', 'time_run', 'time_show',\n",
    "       'time_switch', 'url'], axis = 1)\n",
    "    \n",
    "    # For df_info, we need to add in the RefID for future extraction\n",
    "    # The file_count is used as a unique identifier here\n",
    "    df_info['RefID'] = file_count\n",
    "    \n",
    "    # The base amount in all cases is $20, with 0 delay\n",
    "    # This is added in to all rows, along with the unique identifier of the participant (RefID = file_count)\n",
    "    df_choices['BaseAmount'] = 20.0\n",
    "    df_choices['BaseDelay'] = 0\n",
    "    df_choices['RefID'] = file_count\n",
    "    \n",
    "    # Convert all Delays to be in weeks\n",
    "    dict = {\"1 week\" : '1', \"2 weeks\" : '2', \"1 month\": '4',\"3 months\": '12', \"6 months\" : '24', \"1 year\": '52'}\n",
    "    df_choices=df_choices.replace({\"Delay\": dict})\n",
    "    \n",
    "    #Convert the response_time from milliseconds to seconds\n",
    "    df_choices['duration_in_seconds'] = df_choices['duration'] / 1000.0\n",
    "    \n",
    "# Each participant has entered Financial Distribution data in a different way\n",
    "# May be easiest to manually convert? \n",
    "    #     # Convert Financial Distribution data from % to float\n",
    "    \n",
    "#     df_info['Essentials'] = df_info['Essentials'].str.rstrip('%').astype('float') / 100.0\n",
    "#     df_info['Investments'] = df_info['Investments'].str.rstrip('%').astype('float') / 100.0\n",
    "#     df_info['Leisure'] = df_info['Leisure'].str.rstrip('%').astype('float') / 100.0\n",
    "    \n",
    "#     # Ensure that the distribution of expenses adds up to 1\n",
    "#     df_info['SumOfExpenses'] = df_info['Essentials'] + df_info['Investments'] + df_info['Leisure']\n",
    "#     df_info['valid'] = df_info['SumOfExpenses'] == 1.0\n",
    "#     incorrect = df_info[df_info['valid'] == False]\n",
    "    \n",
    "#     # If the expenses don't add up, send a message to the console\n",
    "#     if(not(incorrect.empty)):\n",
    "#         print(\"Expenses don't add up!: \\n\", incorrect)\n",
    "    \n",
    "#     # Drop the additional columns after checking\n",
    "#     df_info = df_info.drop(['SumOfExpenses', 'valid'], axis = 1)\n",
    "    \n",
    "    # If the page timed out i.e. the choice ended without the response being entered, send a message\n",
    "    # to the console\n",
    "    timed_out = df_choices[df_choices['ended_on'] != 'response']\n",
    "    \n",
    "    if(not(timed_out.empty)):\n",
    "        print(\"Some responses were not collected because of a time out!: \\n\", timed_out)\n",
    "    \n",
    "    # Drop rows where choices timed out\n",
    "    df_choices = df_choices[df_choices['ended_on'] == 'response']\n",
    "    # After this, the 'ended_on' column does not have any further purpose\n",
    "    df_choices = df_choices.drop(['ended_on'], axis = 1)\n",
    "\n",
    "\n",
    "    \n",
    "    # print(df_info.head())\n",
    "    # print(df_choices.head())\n",
    "    \n",
    "    # Write off info & choice data\n",
    "    df_info.to_csv(\"./../Cleaned_Data/Info{}.csv\".format(file_count), index = False)\n",
    "    df_choices.to_csv(\"./../Cleaned_Data/Choice_{}.csv\".format(file_count), index = False)\n",
    "        \n",
    "    \n",
    "    # For analysis, it may be easier to have all choice and participant information in a single dataframe\n",
    "    # This is done after writing the choice data off to separate .csv\n",
    "    df_choice_and_info = df_choices\n",
    "    \n",
    "    df_choice_and_info['Age'] = df_info['Age'].item()\n",
    "    df_choice_and_info['Degree'] = df_info['Degree'].item()\n",
    "    df_choice_and_info['Essentials'] = df_info['Essentials'].item()\n",
    "    df_choice_and_info['Investments'] = df_info['Investments'].item()\n",
    "    df_choice_and_info['Leisure'] = df_info['Leisure'].item()\n",
    "    df_choice_and_info['Happiness'] = df_info['Happiness'].item()\n",
    "    df_choice_and_info['Sleep'] = df_info['Sleep'].item()\n",
    "    df_choice_and_info['Stress'] = df_info['Stress'].item()\n",
    "    \n",
    "    df_choice_and_info.to_csv(\"./../Cleaned_Data/Choice_And_Info_{}.csv\".format(file_count), index = False)\n",
    "    \n",
    "    # Store all participant info, choice info, and combined info in separate databases\n",
    "    # This will provide flexibility while performing data analysis\n",
    "    # Code can be modified later according to the chosen Data Analysis Strategy \n",
    "    if(file_count == 1):\n",
    "        df_all_info = df_info\n",
    "        df_all_choice = df_choices\n",
    "        df_all_choice_and_info = df_choice_and_info\n",
    "    else:\n",
    "        df_all_info = df_all_info.append(df_info)\n",
    "        df_all_choice = df_all_choice.append(df_choices)\n",
    "        df_all_choice_and_info = df_all_choice_and_info.append(df_choice_and_info)\n",
    "        \n",
    "    # Onto the next file!\n",
    "    file_count = file_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write off all patient information to a separate .csv\n",
    "df_all_info.to_csv('./../Combined_Data/ParticipantInfo.csv', index = False)\n",
    "df_all_choice.to_csv('./../Combined_Data/ParticipantChoices.csv', index = False)\n",
    "df_all_choice_and_info.to_csv('./../Combined_Data/ParticipantInfoAndChoices.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
